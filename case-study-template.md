# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: какое количество памяти использует программа для файла размером 20000 строк. Начальное значение - около 82 МБ.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за ~30 секунд

Вот как я построил `feedback_loop`:
1. Изучал отчеты профилировщиков
2. Вносил изменения в программу
3. Запускал тесты для проверки корректности работы программы
4. Запускал тесты производительности

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
1. Гемом memory_profiler;
2. Stackprof;
3. Ruby-prof в режиме graph;
4. Ruby-prof в режиме callstack;
5. Ruby-prof в режиме flat;
6. Ruby-prof с визуализацией в QCacheGrind.

Вот какие проблемы удалось найти и решить

### Выделение 15мб памяти для парсинга даты
- какой отчёт показал главную точку роста: гем memory_profiler
- как вы решили её оптимизировать: убрал лишние вызовы метода map, а также переводы в различные форматы
- как изменилась метрика: выделение памяти снизилось до 24.6 Мб
- как изменился отчёт профилировщика: проблема перестала быть главной точкой роста

### Большое количество аллокаций для метода String#upcase
- какой отчёт показал главную точку роста: Stackprof
- как вы решили её оптимизировать: Всего было 4 вызова метода upcase, все они были использованы для браузеров сессий. Я оставил только 1 вызов метода upcase - при парсинге браузера сессий, тогда все остальные вызовы можно убрать
- как изменилась метрика: снизилась до 23 МБ
- как изменился отчёт профилировщика: проблема перестала быть главной точкой роста

### Выделение большого количества памяти при сборе данных о пользователе
- какой отчёт показал главную точку роста: Ruby-prof в режиме graph
- как вы решили её оптимизировать: изначально блок кода выглядел так:
  ```
  user_key = "#{@user['first_name']}" + ' ' + "#{@user['last_name']}"
  user_data = {
    'sessionsCount' => @user_sessions.count,
    'totalTime' => @user_sessions.map {|s| s['time']}.map {|t| t.to_i}.sum.to_s + ' min.',
    'longestSession' => @user_sessions.map {|s| s['time']}.map {|t| t.to_i}.max.to_s + ' min.',
    'browsers' => @user_sessions.map {|s| s['browser']}.sort.join(', '),
    'usedIE' => @user_sessions.map{|s| s['browser']}.any? { |b| b =~ /INTERNET EXPLORER/ },
    'alwaysUsedChrome' => @user_sessions.map{|s| s['browser']}.all? { |b| b =~ /CHROME/ },
    'dates' => @user_sessions.map{|s| s['date']}.sort.reverse
  }
  ```
  В нем я изменил конкатенацию строк, лишние приведения значений к типу int, использовал bang-методы, где это возможно. В результате данный блок кода стал выглядеть следующим образом:

  ```
    user_key = "#{@user['first_name']} #{@user['last_name']}"
    user_data = {
      'sessionsCount' => @user_sessions.count,
      'totalTime' => @user_sessions.map {|s| s['time']}.sum.to_s + ' min.',
      'longestSession' => @user_sessions.map {|s| s['time']}.max.to_s + ' min.',
      'browsers' => @user_sessions.map {|s| s['browser']}.sort!.join(', '),
      'usedIE' => @user_sessions.map{|s| s['browser']}.any? { |b| b =~ /INTERNET EXPLORER/ },
      'alwaysUsedChrome' => @user_sessions.map{|s| s['browser']}.all? { |b| b =~ /CHROME/ },
      'dates' => @user_sessions.map{|s| s['date']}.sort!.reverse!
    }
  ```

- как изменилась метрика: снизилась до 18 МБ
- как изменился отчёт профилировщика: главная проблема не является главной точкой роста

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 80 МБ для файла размеров 20000 строк до 40 МБ на протяжении всей работы программы для основного файла и уложиться в заданный бюджет.

Также хочу отметить, что программа сейчас работает быстрее, чем программа из первого домашнего задания. Удалось добиться результата в 27 секунд.  

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал performance-test, который проверяет, что программа потребляет менее 40 МБ памяти для файла data_large.txt 
