# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *тут ваша метрика*

Написал бенчмарк на RSS. Получилось:

rss before #work: 26 MB
rss after #work: 929 MB

Если использовать "GC.start(full_mark: true, immediate_sweep: true)"
получается:

rss before #work: 27 MB
rss after #work: 666 MB



## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:
profiling -> recognize hot spot -> modify -> test -> repeat -> commit

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:

- memory_profiler
- ruby_prof: flat, dot (отчет получился кривым), graph, callstack
- callgrind

Вот какие проблемы удалось найти и решить

### String.split + Report#parse_session + Report.collect_stats_from_user

callgrind и callstack показали главные точки роста:

49.12% (49.21%) String#split
23.49% (23.54%) Report#collect_stats_from_user
12.14% (12.16%) Report#parse_session

memory_profiler также указал на эти локации
4.00 MB  /Users/shiv/optimisation/rails-optimization-2-task2/task-2.rb:36
1.81 MB  /Users/shiv/optimisation/rails-optimization-2-task2/task-2.rb:77
1.02 MB  /Users/shiv/optimisation/rails-optimization-2-task2/task-2.rb:93

Плюс что именно там аллоцировалось
5.30 MB  String
3.13 MB  Hash
2.61 MB  Array

Allocated String Report
-----------------------------------
7797  "session"
2839  "INTERNET"
1514  "0"
и так далее...

Тут было очень много инфы по тому сколько дублируется строк, поэтому я сразу добавил # frozen_string_literal: true

Понятно, что split тут не оказаывает особого влияния на использование памяти. Тут просто из кода видно что в прошлом задании я сделал так что в памяти хранится инстанс @summary,
который содержит огромное количество хешей по юзерам. Поэтому чтобы в этом убедиться я закомментил строку сохранения хешей, и сделал бенчмарк еще раз и он показал что вся
память уходит туда.

Дальше. Понятно что нельзя хранить такое кол-во хешей в течение выполнения программы, поэтому формировать json нужно inline, я подумал как это
сделать, обновил код, прогнал тест, сделал бенчмарк на файл data_large.txt еще раз и вот что он показал:

rss before array allocation: 26 MB
rss before #work: 26 MB

rss after #work: 36 MB

Сделал коммит

Результат:
Уложился в бюджет.


Дальше настроил valgrind под мак. Программа сначала потребляет 34.5mb. Пик нагрузки 42.6mb (см скриншот)
[Screenshot](valgrind_screenshot.jpg)
