# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: кол-во аллоцируемой памяти, стартовая точка 3.78 GB

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10 сек

Вот как я построил `feedback_loop`:
Сделал файл на 30к строк и дальше начал работать по шаблону:
- Тестовый запуск
- Внесение в код изменений
- Повторный запуск
- Повторный анализ метрик
- Commit/Revert

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался MemoryProfiler, StackProf, RubyProf

## Вот какие проблемы удалось найти и решить

### Ваша находка №1
- Какой отчёт показал главную точку роста
- MemoryProfiler показал проблему в строках 52 и 53
- Как вы решили её оптимизировать
- Использовал более оптимальное добавление значений в массив
- Как изменилась метрика
- Аллоцирование памяти снизилась до 1.12 GB

### Ваша находка №2
- Какой отчёт показал главную точку роста
- Без метрики
- Как вы решили её оптимизировать
- Переписал программу на более оптимизированный по памяти код в целом
- Как изменилась метрика
- Аллокация памяти снизилась до 92.97 MB

### Ваша находка №3
- Какой отчёт показал главную точку роста
- MemoryProfiler показал, что главная точки роста в строке 181 - при парсинге даты
- Как вы решили её оптимизировать
- Решил не парсить дату и не делать лишних циклов соотвественно
- Как изменилась метрика
- Аллокация памяти снизилась до 71.07 MB

### Ваша находка №4
- Какой отчёт показал главную точку роста
- MemoryProfiler показал, что главная точки роста в строке 100 - String#split
- Как вы решили её оптимизировать
- Решил вынести в константу и зафризить делитель
- Как изменилась метрика
- Аллокация памяти снизилась до 68.85 MB

### Ваша находка №5
- Какой отчёт показал главную точку роста
- MemoryProfiler показал, что главной точки роста осталась строка 100 - String#split
- Как вы решили её оптимизировать
- Я заметил что мы делаем лишний split, решил обойтись одним split'ом
- Как изменилась метрика
- Аллокация памяти снизилась до 57.40 MB 

### Ваша находка №6
- Какой отчёт показал главную точку роста
- Главной точкой роста осталась строка 100 с String#split, не знаю что ещё с ней можно сделать, начал работать над другим кодом. Следующей точкой роста оказалась строка 140 с конкатенацией строк
- Как вы решили её оптимизировать
- Переписал конкатинацию строк на интерполяцию
- Как изменилась метрика
- Аллокация памяти снизилась до 52.25 MB

### Ваша находка №7
- Какой отчёт показал главную точку роста
- Следующая точка роста - строка 142, кажется не совсем эффективно ходить несколько раз по массиву, чтобы собрать статистику пользователя
- Как вы решили её оптимизировать
- Переписал блоки кода для сбора статистики по пользователю, чтобы собирать её за одну итерацию
- Как изменилась метрика
- Аллокация памяти снизилась до 38.57 MB

### Ваша находка №8
- Какой отчёт показал главную точку роста
- MemoryProfiler указал на 89 строку `cols = line.split(LINE_DIVIDER)`, только это место теперь жрёт внушительную часть памяти, остальные метрики незначительны, есть ещё идеи как можно оптимизировать алгоритм программы
- Как вы решили её оптимизировать
- Решил попробовать использовать символы вместо строк для ключей хешей, результат не изменился, совсем не изменился
- Вынес в константы и зафризил строки 'user' и 'session' - Алокация памяти снизилась до 36.17 MB
- Сделал подсчёт всего в одной итерации - 34.35 MB, результат не стоил затраченных усилий
- Как изменилась метрика
- Аллокация памяти снизилась до 34.35 MB

### Ваша находка №9
- Какой отчёт показал главную точку роста
- MemoryProfiler всё так-же 89 строка `cols = line.split(LINE_DIVIDER)`
- Как вы решили её оптимизировать
- Переписал программу в полностью потоковом режиме
- Как изменилась метрика
- Аллокация увеличилась до 36.29 MB
- Общее потребление снизилось с 1210 MB до 37 MB при обработке файла data_large.txt

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с невозможности завершения скрипта с входным файлом `data_large`, до успешного завершения скрипта за 6.3 секунды и потреблением 38 MB памяти. Тем самым мы уложились в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
