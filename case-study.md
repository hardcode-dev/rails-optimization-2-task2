# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы, была поставлена задача использовать такую метрику: "Потребление оперативной памяти"

Чтобы понимать, на какой бюджет мы можем расчитывать, для начала хотелось бы оценить, какой бюджет мы имеем в данный момент. Для этого я несколькими способами решил оценить текущие требования по памяти

### Способ 1: ps -o rss

![ Эй, парень, не хочешь немного дебага? ](screenshots/psorss.jpg)

На разных объемах данных я погонял тесты и попросил по результатам выполнения вывести мне данные, доступные из утилиты ps
```ruby
"MEMORY USAGE: %d MB" % (`ps -o rss= -p #{Process.pid}`.to_i / 1024)
```
Получив следующие значения, я сделал вывод, что с ростом количества строк будет расти и потребление оперативной памяти, в соотношении примерно 3^N, где N- разница в порядке количества строк (при увеличении количества строк в 10 раз потребление памяти растет примерно в 3 раза).

1_000 lines => 37Mb
10_000 lines => 92Mb
100_000 lines => 250Mb

Результат очень приблизительный, однако задачи оценить точный бюджет у нас нет. Если допустить, что рассчеты произведены верно, то на 3.5M строках данных затраты по памяти должны составить 1-1.5 GB. Жирно.

Видим, что количество памяти, используемое на 1000 строчках кода равняется 37 MB- попробуем уложиться в этот результат * 1.5, т.е. в 50 MB.

### Способ 2: Valgrind

Заводим Docker, Valgrind, кофемашину и запускаем программу на 30к строках данных

![ Valgrind ](screenshots/valgrind_30k.png)

Видим линейный рост памяти O(N), понимаем, что так мы не уложимся ни в какие бюджеты. Хотим сделать постоянный расход памяти O(1).

Из интересного: Valgrind показывает рост памяти почти до 1GB, в то время как обычный ps-o-rss показывает нам 251MB. Предоложу, что оверхед связан с запуском самого валгринда, но не уверен.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
Перепишем этот тест с использованием библиотеки ~~Cucumber~~ Rspec
![ Вообще с такой картинкой лучше бы на Cucumber переписали ](screenshots/why_rspec.jpg)

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:
В первую очередь я внес изменения в интерфейс самой программы, позволив передавать ей имя файла, с которым она будет работать.
Дальше я переключил проверку результатов из сравнения строк в сравнение json объектов.
Так же я подключил библиотеку rspec-benchmark и использовал #perform_allocation matcher чтобы зафиксировать текущие метрики потребления памяти.

Так же добавим тест по памяти
```ruby
context 'works on 1_000 lines within 70 MB' do
  let(:size) { 1_000 }

  it {
    prepare_data(size) do |filename|
      expect {
        work(filename)
      }.to perform_allocation(70 * 1024 * 1024).bytes
    end
  }
end
```
Опять же, интересный момент, что ps-o-rss показывает нам расходы в 50MB, в то время как тест дешевле, чем за 70MB не проходит. Спишем оверхед, опять же, на инфраструктурные расходы
На выходе получаем feedback-loop в 15 секунд, можно и побыстрее, если уменьшить количество строк кода, но в целом ожидаю, что после перевода на потоковый подход работать станет итак сильно быстрее

Так же добавим скриптик ./generate.sh и поправим ./test.rb, чтобы запускать программу на разных сетах данных было просто
```bash
./test.rb $(./generate 100)
```

## Вникаем в детали системы, чтобы найти главные точки роста

Внимательно изучив содержимое файла с данными, я обнаружил интересную закономерность: все пользователи идут по порядку и все данные о сессиях пользователя идут следом за строкой с информацией о пользователе.
Таким образом, если предположить, что информация и в дальнейшем будет поставляться в таком формате- я действительно могу переключиться в полностью потоковый режим. Если бы такое предположение было бы ошибочно и данные в файле шли вперемешку, пришлось бы придумывать что-то другое, как вынос результатов по каждому пользователю в отдельный файл или хранение большего объема промежуточных данных в оперативной памяти, или систему индексов для поиска данных пользователя в общем файле.

Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №2
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №X
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
