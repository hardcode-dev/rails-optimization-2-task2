# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решилa исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: объем потребляемой памяти не должен превышать 70 МВ

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроила эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений

Вот как я построил `feedback_loop`:
1. Перед первым циклом заменяем программу оптимизированной по потреблению CPU версией.
2. Фиксируем значение потребляемой памяти.
3. Профилируем, определяем точку роста.
4. Рефакторим код с акцентом на точку роста.
5. Фиксируем новое значение потребляемой памяти и делаем выводы.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*
Для исходного кода:
```Performance allocations is expected to perform allocation of 10 objects
     Failure/Error: it { expect { work('data.txt') }.to perform_allocation(10) }
       expected block to perform allocation of 10 objects, but allocated 1015 objects
```

Для моего кода из task-1
```1) Performance allocations is expected to perform allocation of 10 objects
     Failure/Error: it { expect { work('data.txt') }.to perform_allocation(10) }
       expected block to perform allocation of 10 objects, but allocated 319 objects
```

Вот какие проблемы удалось найти и решить

### Loop №1 - строки
MEMORY USAGE: 2242 MB - 'data_large.txt',
MEMORY USAGE: 315 MB - 'data100_000.txt'
- MemoryProfiler показал, что сaмый высокий уровень потребления памяти у строк (class String) особенно там где `split(',')`
- Решение: заморозить строковые литералы
- MEMORY USAGE: 278 MB для 'data100_000.txt', MEMORY USAGE: 2185 MB для 'data_large.txt' - не очень помогло
- отчёт профилировщика изменился слабо, String в топе.

'data_large.txt'
### Loop №2 на втором месте массивы
- MemoryProfiler, RubyProf
- Добавила построчное считывание файла, использую один и тотже объект стракта User для временного хранения данных о пользователе, сбор и обработка данных по одному пользователю и по всех происходит по мере возможности при считывании строки. Собираю данные по прежнему в хэш `report`.
- MEMORY USAGE: 866 MB
- как изменился отчёт профилировщика - объектов User теперь только 1, оьъекты-строки по прежнему лидируют, потом - массивы.

### Loop №3, акцеты не изменились - строки, массивы
- MemoryProfiler, RubyProf
- Стримминговая запись в файл - хэш уже не нужен, общие данные собираю в переменные, данные по пользователю - в объект User, когда считывается строка для следующего пользователя, текущего записываем в файл и объект обнуляем. После считывания всего исходящего файла записываем в файл общие данные. Такой ход избавил от многих переменных, массивов, хеша для сбора данных.
- MEMORY USAGE: 16 MB - это результат в конце выполнения работы, valgrind massif показывает пик 41 MiB
- B Retained осталась одна строка, которая последней записывалась в файл, количество массивов значительно упало

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 2242 MB до 41 MB и уложиться в заданный бюджет.
Время выполнения изменилось от 27.8 секунд до 20 секунд (benchmark)

![Valgrnd-massif chart](https://github.com/rublen/rails-optimization-task2/blob/task2/Screenshot_from_2020-02-16_00-10-02.png)

## Сомнения
memory-prifiler зависает на `data_large`, пробовала на `data100_000.txt`, результат:
```Total allocated: 110.12 MB (1582805 objects)
Total retained:  2.71 kB (1 objects)
...
Allocated String Report
-----------------------------------
     84569  "session"
     84569  /home/lena/optima/rails-optimization-task2/task-2.rb:41

     16350  "0"
     16290  /home/lena/optima/rails-optimization-task2/task-2.rb:41
        30  /home/lena/optima/rails-optimization-task2/task-2.rb:22
        30  /home/lena/optima/rails-optimization-task2/task-2.rb:23

     15431  "alwaysUsedChrome"
     15430  /home/lena/optima/rails-optimization-task2/task-2.rb:43
         1  /home/lena/optima/rails-optimization-task2/task-2.rb:57

     15431  "browsers"
     15430  /home/lena/optima/rails-optimization-task2/task-2.rb:43
         1  /home/lena/optima/rails-optimization-task2/task-2.rb:57
...
```
15431 - это количество пользователей. Значит ли это, что при профилировании замороженные литералы не сработали?
Та же ситуация с rspec-performance - для 'data.txt' количество объектов почти не изменилось с моментa начала работы. Тест:
```it { expect { work('data.txt') }.to perform_allocation(10) }```
Результат:
```
Failure/Error: it { expect { work('data.txt') }.to perform_allocation(10) }
       expected block to perform allocation of 10 objects, but allocated 325 objects
```

## Защита от регрессии производительности
Не удается. Разве что так:
```it { expect { work('data.txt') }.to perform_allocation(325) }```


## Checklist
- [x] Построить и проанализировать отчёт гемом `memory_profiler`
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `Flat`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `Graph`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `CallStack`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `CallTree` c визуализацией в `QCachegrind`;
- [x] Построить и проанализировать текстовый отчёт `stackprof`;
- [ ] Построить и проанализировать отчёт `flamegraph` с помощью `stackprof` и визуализировать его в `speedscope.app`;
- [x] Построить график потребления памяти в `valgrind massif visualier` и включить скриншот в описание вашего `PR`;
- [ ] Написать тест, на то что программа укладывается в бюджет по памяти
