# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: количество потребляемой памяти при просчете 100к записей (885 мб на старте, 11.4 секунды)

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: профилирование - изменение кода - тестирование – бенчмаркинг – откат при отсутствии разницы от оптимизации/сохранение результатов

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memoty_profiler, ruby-prof (allocation/memory), stackprof (allocation), valgrind

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- memory_profiler показал, что больше всего памяти `3587123560` аллоцируется в `task-2.rb:74` (по классу лидирует`5212433896  Array`, что похоже на то, что происходит в `task-2.rb:74`)
- вместо создания нового массива `sessions = sessions + [parse_session(line)] if cols[0] == 'session'` будем использовать пуш `<<` в уже определенный массив (для аналогично для `users`).
- метрика снизилась с 885 до 287 мб
- профилировщик показывает `1305579360  task-2.rb:128` как лидирующую позицию. Количество аллоцированных массивов снизилось до `1499267656  Array`

### Ваша находка №2
- memory_profiler показал, что больше всего памяти `1305579360` аллоцируется в `task-2.rb:128` (по классу лидирует`1499267656  Array`, что похоже на то, что происходит в `task-2.rb:128`)
- заменяем `sessions.select { |session| session['user_id'] == user['id'] }` на поиск по предварительно сформированному хэшу `sessions_by_user =  sessions.group_by { |session| session['user_id'] }`
- метрика снизилась с 287 до 140 мб
- профилировщик показывает `120416072  task-2.rb:132` как лидирующую позицию. Количество аллоцированных массивов снизилось до `206505392  Array`, лидирующее место теперь занимает `344381297  String`.

### Ваша находка №3
- memory_profiler показал, что больше всего памяти `120416072` аллоцируется в `task-2.rb:132` (по классу лидирует `344381297  String`, что не похоже на то, что происходит в `task-2.rb:132`, поскольку там происходят операции с массивами, а не строками).
- вместо `users_objects = users_objects + [user_object]` использую `users_objects << user_object`
- метрика снизилась незначительно, будем считать, что это те же 140 мб
- профилировщик показывает `97472465  task-2.rb:169` как лидирующую позицию. Количество аллоцированных массивов снизилось до `86230952  Array`, лидирующее место по-прежнему занимает `344381297  String`.

### Ваша находка №4
- memory_profiler показал, что больше всего памяти `97472465` аллоцируется в `task-2.rb:169` (по классу лидирует `344381297  String`, что похоже на то, что происходит в `task-2.rb:169`)
- заменяю `user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 }` на `user.sessions.map{|s| s['date']}.sort { |d1, d2| d2 <=> d1 }`
- метрика снизилась с 140 до 133 мб
- профилировщик показывает `96369656  json-2.7.2/lib/json/common.rb:220` как лидирующую позицию. Количество аллоцированных строк снизилось до `313934727  String`, это по-прежнему лидирующая позиция.

### Ваша находка №5
- профилировщик показывает `96369656  json-2.7.2/lib/json/common.rb:220` как лидирующую позицию
- вместо записи/чтения файла из каждого треда, агрегирую репорты из каждого треда, после чего 1 раз пишу ее содержимое в файл
- метрика снизилась с 133 до 58 мб
- профилировщик показывает `48221760  task-2.rb:72` как лидирующую позицию. Количество аллоцированных строк снизилось до `160207766  String`, это по-прежнему лидирующая позиция.

### Ваша находка №6
- профилировщик показывает `48221760  task-2.rb:72` как лидирующую позицию, но дальнейшие попытки оптимизации не приводят к снижению потребляемой памяти: основной точкой роста является ограничение накапливаемых данных
- переписываю программу в потоковом стиле (накапливаем данные только по 1 пользователю и его сессиям за раз, после накопления собираем статистику, пишем в файл и начинаем сначала)
- снизилась до 21мб для 100к (для всего файла тоже 21мб)
- количество строк сократилось до `51749209  String`

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 885мб до 21мб и уложиться в заданный бюджет (70мб).

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были написаны тесты на асимптотику, время работы и количество аллоцированных объектов на 10к строк 