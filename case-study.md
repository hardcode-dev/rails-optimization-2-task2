# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: измерять размер памяти, который потребляет процесс. Независимо от времени выполнения, процесс не должен превышать 70мб. Были подготовлены слайсы данных: 1%, 5% и 10% от общего объема. Профилирование проводилось на 5%. Для измерения потребления RAM использовалась команда:
```bash
ps -o rss= -p #{Process.pid}`.to_i / 1024
```

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 20-30 mb.

Вот как я построил `feedback_loop`:
1. Запускал профилировщик, строил отчет, находил основную точку роста.
2. Вносил в код изменения, чтобы сократить потребление памяти в основной точке роста.
3. Запускал тест, чтобы убедиться, что программа работает корректно.
4. Запускал профайлер, чтобы убедиться, что внесенные изменения сокращают потребление памяти программы.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory_profiler

Вот какие проблемы удалось найти и решить

### Излишнее создание массива при парсинге сессии
При парсинге строчки с сессией использовался оператор += [arr], вместо более дешевого <<, сокращение потребления памяти: 3405mb -> 507mb.

### Аллокация нового массива сессий пользователя из общего массива сессий
Оптимизация тяжелого `select`'a для выбора сессий конкретного пользователя, было принято решение хранить все сессии в хэше, по ключу, где ключ - <first_name> + <last_name>, значение массив сессий, сокращение потребления памяти: 507nb -> 489mb.

### Излишнее создание массива при парсинге пользователей
При парсинге строчки с пользователем использовался оператор += [arr], вместо более дешевого <<, сокращение потребления памяти: 489mb -> 392mb.

### Излишний split на строку
При обходе всего файла в методы парсинга сессии и пользователя передавалась строка, вместо уже полученного массива атрибутов, было принято решение передать заранее полученный массив, сокращение потребления памяти: 392mb -> 296mb.

### Date.parse
При использовании метода Date.parse аллоцировались дополнительные ненужные объекты, было принято решение записывать дату в исходном формате, обрезая в конце `\n`, сокращение потребления памяти: 296mb -> 233mb.

### Работа с файлом построчно
После всех перечисленных оптимизация стало понятно, что хранить все объекты сессий и пользователей очень дорого, поэтому было принято решение записывать данные о пользователе в результирующий файл построчно и дописать в конце данные для общего отчета (т.к. порядок строк исходного файла позволяет это сделать).
Сокращение потребления памяти: 233mb -> 23mb.

### Сеарилизация в JSON, используя gem Oj
Последней стадией оптимизации стало замена стандартной JSON библиотеки на Oj, что не повлияло на потребление памяти, но ускорило программу на 10 секунду (40 -> 30).

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с ~3400mb до 23-30 mb

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написал тест, который проверяет, что программа не использует более 40mb.
