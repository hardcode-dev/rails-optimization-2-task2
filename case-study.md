# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
*Скорость обработки файла*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10-15 секунд

Вот как я построил `feedback_loop`:

Так как измерить скороть обработки файла data_large.txt скриптом без оптимизации не представляется возможным, было принято решение подготовить несколько
наборов тестовых данных размером в 0.5mb, 1mb, 5mb, 25mb, 60mb и использовать их последовательно, переходя к большему объему тестового файла,
если скрипт обрабатывал объем менее чем за 10 секнунд.

Подготовим файлы подходящего объема
- wc data_large.txt - в файле 3кк строк (134 mb) ~ 30к строк на mb
- head -15000 data_large.txt > data05mb.txt
- head -30000 data_large.txt > data1mb.txt
- head -150000 data_large.txt > data5mb.txt 
- head -750000 data_large.txt > data25mb.txt
- head -1800000 data_large.txt > data60mb.txt

Далее модифицируем скрипт таким образом, чтобы можно было удобно вызывать его, передавая название обрабатываемого файла и выводя время обработки файла.
Каждый раз, запуская обработку файла, запускаем тест и убеждаемся, что программа работает корректно, выводим время обработки файла.

## Вникаем в детали системы, чтобы найти главные точки роста
Попробуем отключить GC, посмотрим, на сколько это повлияет на скорость обработки файла 0.5mb
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 12.421244000001025 sec
- устанавливаем GC.disable
- запускаем ruby task-1.rb data05mb.txt... processed data05mb.txt in 11.271920999999566 sec
Есть некоторый прирост, но он составляет всего 10-15%. Судя по всему на данном этапе проблемой является вычислительная сложность алгоритма, 
а не потребление памяти. Попробуем найти самые горячие точки и "точки роста". 

### rbspy
Для начала я попробовал исследовать программу при помощи профилировщика rbspy
- sudo rbspy record --pid 55384 

Отчет rbspy не дал какой-то конкретной информации, однако строчка 

- 12.79   100.00  c function - unknown

Может говорить, что большая часть работы производится некой внешней С библиотекой. Продолжим исследование

### ruby-prof
Попробуем исследовать программу при помощи профилировщика ruby-prof в разных режимах

- gem install ruby-prof
- require 'ruby-prof'

### ruby-prof flat - Array#select
Во flat отчете ruby-prof видно, что максимум времени выполнения скрипта занимает функция Array#select
- %self      total      self      wait     child     calls  name                           location
- 89.11     11.330    11.330     0.000     0.000     2288   Array#select

Метод select используется в единственном месте программы, строка 105.
В данный момент это самая горячая точка программы, попробуем ее оптимизировать.
Исходное значение метрики оптимизации - 12 секунд (файл 0.5mb), пробуем внести изменения в код.

Попробуем полностью избавиться от метода select, а парсинг сессий пользователей провести прямо в методе file_lines.each
при первоначальном чтении файла, сразу сохраняя сессиии в user_sessions_hash. 

Время разбора файла размером 0.5mb сократилось до 2-x секунд. Коммитим изменения.

### Оценка результатов первой оптимизации
Так как парсинг файла data1mb.txt занимает всего 3 секунды, сразу переходим к data5mb.txt
Оценим текущее состояние метрики
- process data5mb.txt ...
- ... processed data5mb.txt in 47.406245999998646 sec

Результат в 47 секунд оставляет желать лучшего. Так же становится ясно, что время работы скрипта увеличивется 
значительно быстрее увеличения размера файла.

Попробуем отключить GC, чтобы оценить его внияние на работу скрипта на объеме данных в 5mb.

Дождаться выполнения скрипта не удалось, похоже что скрипт потребляет всю доступную память и своп, после чего все зависает.

Попробуем вернуться к профилированию через ruby-prof.

### ruby-prof Array#each
Запустив ruby-prof во flat режиме еще раз, можно увидеть новый топ метод по времени работы - Array#each
- %self      total      self      wait     child     calls  name                           location
- 85.17     46.393    39.992     0.000     6.401       10   Array#each
- 5.02      2.372     2.357     0.000     0.015   150000   Array#all?

Array#each вызывается в нескольких местах программы. Попробуем сформировать отчет ruby-prof в GraphHtml.
Подозрение падает на Array#each вызванный из Object#work, это место выглядит явно не оптимальным,
так как тут происходит чтение полного файла в память. Однако, рефакторинг с построчнми чтением файла не дает прироста
производительности.

Rbspy все так же показывает в топе c function - unknown. Выжать что-то большее из GraphHtml и flat не удается

Пока откатываю все изменения обратно, решаю попробовать ruby-prof в режиме CallStack

Так как файл размером 5mb обрабатывается достаточно долго, решил добавить промежуточный объем 3mb
- head -90000 data_large.txt > data3mb.txt

Из отчета CallStack стало понятно, что ruby-prof не может разделить вызовы Array#each внутри Object#work, 
поэтому я решил провести рефакторинг и разнести вызовы each в отдельные методы.

Значение метрики оптимизации - 10 секунд (файл 3mb)

Я выделил два новых метода, parse_file и process_line, переписал чтение файла на построчный режим. 
Это улучшило метрику всего на 1 секунду, то-есть основная проблема производительности не была 
в данном моменте связана с чтением файла. Тем не менее, метрика улучшилась, зафиксируем результат  

#String#split
В этом месте я обратил внимание на следующие строки в отчете ruby-prof CallStack:
- 76.83% (100.00%) <Class::IO>#foreach [1 calls, 1 total]
- 2.38% (3.10%) Object#process_line [90000 calls, 90000 total]
- 1.90% (79.64%) String#split [90000 calls, 180000 total]

Тут можно заметить, что Object#process_line вызывается 90000 раз - это сответствует количеству строк в файле размером 3mb
А String#split вызывается 180000 total - в три раза больше. Возможно, split реализована низкоуровнево, и это именно она та 
самая c function - unknown в отчете rbspy. 

Попробуем найти все вызовы split и изменить код таким образом, чтобы вызывать ее не более 1 раза для каждой строки файла с данными.

Значение метрики оптимизации - 16 секунд (файл 3mb), внесем изменения в код

После переписывания кода количество вызовов split сократилось до количества строк в файле, однако значение метрики почти не изменилось.
Принимаю решение коммитить изменения, так как метрика не стала хуже, а код стал более понятным и читаемым

#Оценка результатов воторй оптимизации

После второго раунда оптимизации значение метрики практически не улучшилось. Кроме того, отчет ruby-prof CallStack
выглядел очень странно 
- 75.51% (100.00%) <Class::IO>#foreach [1 calls, 1 total]
- > 1.70% (2.25%) Object#process_line [90000 calls, 90000 total]
- >> 1.19% (69.97%) String#split [90000 calls, 180000 total]
- > 1.57% (2.07%) Object#parse_session [76100 calls, 76100 total]

Метод <Class::IO>#foreach потребляет 75% процессорного времени, однако оба вызванных им методоа потребляют всего 1,5-2%.
В сумме с беспрецедентным жором памяти скриптом при отключенном GC, я сделал предположение, что остальное время тратится 
как раз на сборку мусора. Возможно, как раз работу GC rbspy показывал как c function - unknown

# users = users + [user]
После выделения чтения файла в отдельный метод, понятно, что искать проблему с потреблением памяти надо именно в нем.
В строках 64 и 69 мы видим констркции вида users = users + [user] и sessions = sessions + [session]. Оптимизируем этот код,
чтобы не создавать слишком много объектов.

Значение метрики оптимизации - 19 секунд (файл 3mb)
После внесения изменений в код с использованием оператора << значение метрики упало до 5-и секунд. Коммитим.

# Date.parse
Продолжим изумение скрипта. В отчете ruby-prof CallStack обнаруживается метод Date#parse, занимающий значительную часть
процессорного времени. Данный метод вызывается в скрипте один раз, в строке 160. Из лекции мы знаем, что Date#parse очень медленный метод. 
Посмотрим, можем ли мы привести даты к формату iso8601 менее затратным способом

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 47.07% (47.07%) Array#each [2 calls, 9 total]
- >> 26.81% (56.96%) Array#map [253671 calls, 253673 total]
- >>> 18.92% (70.57%) <Class::Date>#parse [126939 calls, 126939 total]

Так как файл размером 3 мегабайта обрабатывается слишком быстро, переходим к использованию файла размером 5mb.
Значение метрики оптимизации - 9.9 секунд (файл 5mb). Попробуем внести изменения в код.

При ближайшем рассмотрении кажется, что даты в файле уже в формате iso8601, и можно их вообще не конвертировать. 
Метрика уменьшается до 7 секунд, коммитим.

# Array#all?
Пока не удается перейти к обработке файла размером 25mb, так как она занимает более 60-и секунд,
остаемся на файле размером 5mb. В отчете ruby-prof CallStack видим следующее:

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 61.89% (61.89%) Array#each [2 calls, 9 total]
- >> 28.68% (46.35%) Array#all? [150000 calls, 150000 total]

Метод Array#all? вызывается в программе в двух местах, нас интересует вызов all? внутри each - а это происходит только
в строке 101. В этом месте обсчитывается количество уникальных браузеров, попробуем перенести эту логику на этап
построчного чтения файла

Значение метрики оптимизации - 7 секунд (файл 5mb), попробуем внести изменения в код.
После оптимизации метрика уменьшается до 5 секунд, коммитим

# Array#map

Снова смотрим в отчет ruby-prof.
Топ метод по времени работы - это Array#each, внутри которого вызываются  Array#map

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 68.57% (68.57%) Array#each [1 calls, 8 total]
- >> 4.57% (6.66%) Array#map [922176 calls, 922178 total]
- >>> 1.08% (1.57%) Hash#merge [806904 calls, 806904 total]

Я обратил внимание на количество вызовов метода map, число очень большое, при этом из лекции мы знаем, что map очень 
затратный в плане производительности метод. Осматривая код скрипта, я обнаружил несколько мест, где map вызывается
последовательно в стиле 
- { 'totalTime' => user.sessions.map {|s| s['time']}.map {|t| t.to_i}.sum.to_s + ' min.' }
Попробуем оптимизировать скрипт, сократив количество вызовов map, объеденив блоки в один.

Значение метрики оптимизации - 5 секунд (файл 5mb), попробуем внести изменения в код.
Количество вызовов map, упало, но целевая метрика уменьшилась всего на 0,5 секунды.
Тем не менее, улучшение есть и код стал более читаемым. Коммитим.

# Array#each
В топ вызываемых методов выходит Array#each, этот метод вызывается в нескольких местах. Выдвигаю предположение, 
что значительную нагрузку создает вызов each c блоком создания объектов 
- User.new(attributes: attributes, sessions: user_sessions)
Для подтверждения теории, выношу создание Users в отдельный метод create_users_objects. Этот метод сразу выходит в 
топ отчета и вызов Array#each в нем так же создает значительную нагрузку.

- 100.00% (100.00%) Object#work [1 calls, 1 total]
- > 44.92% (44.92%) Object#create_users_objects [1 calls, 1 total]
- >> 44.92% (100.00%) Array#each [1 calls, 8 total]

Попробуем оптимизировать данный код, значение метрики оптимизации - 4 секунды (файл 5mb)
В отчете, внутри методов Array#each нет методов, потребляющих заничельное количество ресурсов. Выше уже был похожий момент,
означавший трату ресурсов на работу GC. Изменив потребляющий значительное количество памяти код на 
- users_objects << user_object
удалось уменьшить значение метрики до 3-х секунд. Коммитим

# Оценка результатов третьей оптимизации
Последняя оптимизация позволила взять в работу файл размером 25mb, продолжим исследование.  

# collect_stats_from_users > each
В топ выходит метод collect_stats_from_users и вызывыемый в нем метод each, вызываемый большое число раз.
Рассматривая вызов collect_stats_from_users в строках 120-160 можно увидель, что данный метод делает полный перебор
массива users_objects для каждого из отчетов. Попробуем изменить код таким образом, чтобы все отчеты генерировались
в один проход.

Попробуем оптимизировать код, значение метрики оптимизации - 19 секунд (файл 25mb)

Я убрал передачу блока в метод collect_stats_from_users, перенеся всю логику обсчета статистики в него. 
Метрика упала до 15 секунд. Коммитим.

# upcase, to_i

Метод collect_stats_from_users все еще лидирует. Внутри него можно увидеть два метода - upcase и to_i, 
вызываемые значительное количество раз. Эти методы искользуются в сборе разных показателей статистики, поэтому возникла идея
производить их на этапе parse_session один раз.

- 35.57% (35.57%) Object#collect_stats_from_users [1 calls, 1 total]
- > 35.57% (100.00%) Array#each [1 calls, 2 total]
- >> 15.41% (43.32%) Array#map [691632 calls, 691633 total]
- >>> 1.98% (12.85%) String#upcase [1269456 calls, 1748989 total]
- >>>> 1.79% (11.62%) String#to_i [1269456 calls, 1269456 total]

Значение метрики оптимизации - 15 секунд (файл 15mb), попробуем внести изменения в код. 

Прирост производительности очень не большой, около 0,5 секунды. Тем не менее коммитим. 

В этой точке скрипт начал обрабатывать файл data_large.txt за 85 секунд. Победа близка.

#CallTreePrinter - Array::each
Попробуем запустить ruby-prof в режиме отчета CallTreePrinter. В нем можно обнаружить значительное
количество вызовов Array::each внутри IO::foreach. Похоже, что в топ выходят многочисленные user.sessions.map,
формирующие различные отчеты со статистикой. Попробуем провести рефакторинг таким образом, чтобы запускать перебор
сессий толко один раз. 

Значение метрики оптимизации - 16 секунд (файл 25mb), попробуем внести изменения в код.

Оптимизация почи не помогает, метрика уменьшается всего на 1 секунду. Тем не менее, коммитим

# Оценка результатов четвертой оптимизации

Хотя в четвертом раунде оптимизации не удалось сильно продвинуться, возникло ощущение, что скрипт можно сильно оптимизировать,
если перенести всю логику обсчета статистики внутри блока File.foreach. На данном этапе скрипт сильно упростился, и стало
примерно понятно, что конкретно в нем происходит, и засилье вызовов метода Array#each вызвано как раз формированием
массивов Users и Sessions, с последующим его проходом во вложенных циклах. Попробуем пененести обсчет статискики попунктно
внутрь метода чтения файла. 

Значение метрики оптимизации - 14 секунд (файл 25mb), попробуем внести изменения в код.

Переносим обсчет статистики по сессиям, метрика упала до 13 секунд. Коммитим

# File.foreach и .each

Рассматривая отчет в qcachegrind, я обратил внимание, что время внутри метода work занято вызовами 
двумя методов - File.foreach и .each. Выходит, мы сначала перебираем файл чтобы созать массив
пользователей и сессий, а затем проходим по нему через each, чтобы обсчитать статистику. Возникла
идея перенести обсчет всей статистики внутрь foreach и не перебирать сесии второй раз. Есть ощущение,
что  при этом массив с сессиями в памяти можно будет не создавать вообще. 

Однако тут есть сложность - в момент обсчитывания сессии для построения отчета по сессиям пользователей
все пользователи уже должны быть нам известны + нам нужен некий механизм получения информации о пользователе по его id

Для начала попробуем пропустить файл через File.foreach два раза, сначала собрав пользователей,
затем собрав отчет по сессиям всех уже известных пользователей.

Значение метрики оптимизации - 14 секунд (файл 25mb), попробуем внести изменения в код.

После рефакторинга метрика падает до 12 секунд, коммитим.

# Oj
В отчее в qcachegrind становится заметным большой блок генерации json. Попробуем подключить
более производительный гем oj, заодно добавляю # frozen_string_literal: true - хуже от этого точно не будет

После рефакторинга метрика падает с 12 до 9 секунд (файл 25mb), коммитим.

## Результаты оптимизации по CPU
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы до 9 секунд (файл 25mb) и уложиться в заданный бюджет - обработка файла data_large.txt
заняла 28 секунд.

## Новая актуальная проблема - оптимизация по памяти
Узнав, что теперь мы способны обрабатывать файлы с данными размером 125 МБ за ~ 30 секунд, бизнес
принял решение обсчитывать данные нон-стоп, чтобы понимать статистику посещений ресурса в реальном времени.
Для этих целей был выделен VPS c объемом памяти 70 мегабайт.

Таким образом, потребовалось оптимизировать скрипт таким образом, чтобы потребление 
памяти укладывалось в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы
был внедрен тест производительности, проверяющий скорость обработки файла размером 5мб.
Я установил удовлетворяющую тест скорость в 3 секунды - это дает некоторый запас
от текущей скорости обработки для предотвращения ложных срабатываний, и в то же время не даст
потерять достигнутый при оптимизации CPU прогресс при внесении следующих правок

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я 
придумал использовать такую метрику: *Потребление памяти*

## Feedback-Loop 2
Добавим в скрипт вывод использованной памяти через `ps -o rss= -p #{Process.pid}`.

Так же добавим дополнительные скрипты: `test.rb` который будет запускать прогон тестов
и `prof.rb`, в котором мы будем подключать профилировщики. Это позволит замерять потребление 
памяти скриптом без затратных тестов и профилировщика и исключить их влияние на метрику.

Для начала оптимизации я подготовил файл размером 10 мб

- head -300000 data_large.txt > data10mb.txt

С ним удобно начать работать, так как показатель оптимизируемой метрики для него ~ 195мб, а 
его обработка занимает несколько секунд. Далее, если удастся внести удачные оптимизации, я планирую 
увеличивать обрабатываемый файл вплоть до оригинального data_large.txt

## Memory_profiler
Попробуем подключить memory_profiler. Так как файл размером 10 мб профилируется
слишком долго, используем файл размером 1 мб.
В отчете мы видим:

> allocated memory by class

> 162.82 MB  String

>  95.41 MB  Array

И видим 
> allocated memory by location

> 130.16 MB  /Users/ineedjet/Projects/rails-optimization-2-task2/task-2.rb:42

Похоже, что в этом месте мы создаем значительное количество новых массивов
и строк директивой `cols = line.split(',')`. Попробуем изменить код так, чтобы
не создавать новые объекты, заменив split на цикл while, попробовав посимвольно перебрать строку.

Похоже, что если мы хотим использовать одну и ту же переменную для обработки текущего
символа, придется отказаться от # frozen_string_literal: true. 

Значение метрики 195мб(файл размером 10 мб), попробуем внести изменения в код.

После рефакторинга потребление памяти упало до 182 мб (файл размером 10 мб). Коммитим

## Strings
Так как в прошлом шаге мы разморозили строки, потребление памяти при их создании должно
было сильно вырасти. Memory_profiler показывает в каких строках скрипта создается
большинство одинаковых строк и какие это строки: "," "" "session" "user". Занесем эти строки
в константы, чтобы не создавать объекты кажды раз, а вместо строки '' будем 
использовать метод clear.

Значение метрики 182мб(файл размером 10 мб), попробуем внести изменения в код.

После рефакторинга потребление памяти упало до 170 мб (файл размером 10 мб). Коммитим

## stackprof
В отчете профилировщика stackprof я увидил топ ассоциаций объектов а строке

> char = line.slice(line_index)

я попробовал использовать вместо slice regexp line =~ /^,/, но это не дало выигрыша по памяти.
Для теста я сравнил результат вариантов со slice и regexp с выключенным GC, и regexp оказадлся хуже
(114 MB vs 254 MB). Возвращаем все как было.
