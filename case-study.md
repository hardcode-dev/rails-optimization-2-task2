# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
Измерение количества потребляемой памяти в конце выполнения программы. Объем данных был сокращен до 20.000 строк с целью ускорения фидбек лупа

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
Также был добавлен тест проверяющий соответствие метрики бюджету, чтобы не допустить дальнейшей деградации метрики.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за несколько секунд

Вот как я построил `feedback_loop`:
- Формирование отчета, определение основных точек роста
- Внесение изменений в код
- Прогон тестов, чтобы убедиться что логика выполнения не нарушена
- Измерение количества потребляемой памяти

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я планировал воспользовался ruby-prof профайлером в режиме профилирования памяти (`RubyProf::MEMORY`). Однако что-то пошло не так и профилировщик упал, полагаю это может быть связано с ОС и процессором (Mac c m1).
В качестве альтернативы был выбран `memory_profiler`, как наиболее информативный и наглядный вариант.
Также для подкрепления результатов дополнительно генерировался отчет `RubyProf::ALLOCATIONS`.
Вот какие проблемы удалось найти и решить:

### Ваша находка №1
- `memory_profiler` показал главную точку роста в строке: `sessions = sessions + [parse_session(line)] if cols[0] == 'session'`.
  Текущее значение потребляемой процессом памяти: 220 MB. (memory_profiler 1.70 GB)
- Очевидно что аллоцируется много объектов из за дополнительного создания массивов. Перепишем строку так чтобы ненужные объекты не создавались
- Метрика снизилась: текущее значение потребляемой процессом памяти: 110 MB. (memory_profiler 550 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №2
- `memory_profiler` показал главную точку роста в строке: `user_sessions = sessions.select { |session| session['user_id'] == user['id'] }`.
- Похоже что метов select аллоцирует множество доп. объектов. Т.к исходный файл имеет строгий формат
  (строки сессий юзера идут строго за строкой юзера) - перепишем первый перебор строк, добавив заполнение сессий юзера.
- Метрика снизилась: текущее значение потребляемой процессом памяти: 76 MB. (memory_profiler 138 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №3
- `memory_profiler` показал главную точку роста в строке: `users = users + [parse_user(line)] if cols[0] == 'user'`.
- Находка аналогична случаю из первой итерации. Перепишем в соответствии
- Метрика незначительно снизилась: текущее значение потребляемой процессом памяти: 76 MB. (memory_profiler 100 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №4
- `memory_profiler` показал главную точку роста в строке: `users_objects = users_objects + [user_object]`.
- Находка аналогична предыдущей. Перепишем в соответствии
- Метрика снизилась: текущее значение потребляемой процессом памяти: 62 MB. (memory_profiler 63 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №5
- `memory_profiler` показал главную точку роста в строке:
`{ 'dates' => user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 } }`.
Отчет показывает большое количество аллоцированных объектов.
- Возможно это результат множественных избыточных переборов (map) - оптимизируем этот аспект.
  Также изучение исходных данных показало, что возможно парсинг даты является избыточным.
- Метрика снизилась: текущее значение потребляемой процессом памяти: 60 MB. (memory_profiler 48 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №6
- `memory_profiler` показал новые главные точки роста (примерно равноценные):
`cols = line.split(',')` в методе `work` и `fields = session.split(',')` в методе `parse_session`.
- Нет необходимости трижды (также в методе `parse_user`) создавать массив строки. Попробуем оптимизировать.
- Метрика незначительно снизилась: текущее значение потребляемой процессом памяти: 60 MB. (memory_profiler 39 MB)
- Строка осталась главной точкой роста и в данный момент я не вижу пути ее дальнейшей оптимизации.
  Но все же общее потребление сократилось за счет переиспользования объектов.

### Ваша находка №7
- `memory_profiler` показал, что класс String на первом месте по количеству аллоцированных объектов (на втором по памяти).
  Основная соответствующая точка роста в коде: `user_key = "#{user.attributes['first_name']}" + ' ' + "#{user.attributes['last_name']}"`
- Перепишем строку кода, чтобы объект пробела не создавался каждый раз
- Метрика незначительно снизилась: текущее значение потребляемой процессом памяти: 60 MB. (memory_profiler 35 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №8
- `memory_profiler` показал главную точку роста в строке.
  `report['usersStats'][user_key] = report['usersStats'][user_key].merge(block.call(user))`
- Перепишем строку кода так чтобы дополнительные объекты не создавались
- Метрика незначительно снизилась: текущее значение потребляемой процессом памяти: 60 MB. (memory_profiler 32 MB)
- Строка перестала быть главной точкой роста

### Ваша находка №9
- `memory_profiler` показал несколько главных точек роста:
  `cols = line.split(',')` в методе `work`, метод `parse_session`, а также `file_lines = File.read(filename).split("\n")`.
  Также был измерен объем затраченной памяти для полного объема данных: 1554 MB.
- Из бюджета очевидно, что мы не можем ни считывать файл в память целиком, ни накапливать в памяти данные по пользователям.
  Поэтому попробуем перевести программу на потоковый подход: построчное чтение и запись.
- Метрика снизилась: текущее значение потребляемой процессом памяти: 36 MB. (memory_profiler 25 MB)
  При обработке полного объема данных потребление памяти снизилось до 379 MB.
  Время обработки полного файла сократилось с бесконечности до 9.5 сек.
- Основная метрика приблизилась к бюджету, но все же еще ему не соответствует.

### Ваша находка №10
- `memory_profiler` по прежнему показывает главную точку роста в строке `cols = line.chomp.split(',')`
- Попробуем заставить метод split не пересоздавать массив каждый раз
- Метрика незначительно снизилась: текущее значение потребляемой процессом памяти: 36 MB. (memory_profiler 21 MB)
- Точка роста осталась прежней, однако потребляемая ей память снизилась на 4 MB

## Результаты
В программе по прежнему присутствуют точки роста: `cols = line.chomp.split(',')`, метод `parse_session` и несколько менее значимых,
но дальнейшая оптимизация не дает ощутимых результатов.
Текущая метрика для полного объема данных: 380 - 400 MB. Время обработки: 8.8 сек

UPD: после замены `browsers << session['browser']` на `Set.new` и `browsers.add` объем потребляемой памяти значительно сократился.
Текущая метрика для полного объема данных: 28 MB. Время обработки: 7 сек.
Хотел бы отметить, что профилировщики не показали точку роста в данной строке. Возможно из за недостаточного объема данных

Наиболее полезными профилировщиками оказались memory_profiler и RubyProf::ALLOCATION c CallStack.
RubyProf::MEMORY на маке с m1 упал, найти причину так и не удалось, но подозреваю что решить эту проблему подручными средствами не выйдет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были добавлены тесты потребляемой памяти и затраченного времени
