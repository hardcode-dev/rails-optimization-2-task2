# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *количество потребляемой памяти при обработке файла в течение всей своей работы.*


## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений *с использованнием памяти всего 420 MB*

Вот как я построил `feedback_loop`: 
  1. Для проверки правильности отчета использовал минимальный набор данных (10 000).
  2. Использовал профилировщик для поиска точки роста
  3. Рефакторил код
  4. Повторно проверял результат профилировщика
  5. Запускал общий тест чтобы проверить что ничего не сломал
  6. Коммитил результат

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался 
  1. `memory_profiler`
  2. `ruby_prof`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- `memory_profiler` - Показал что точка роста в строке `sessions = sessions + [parse_session(line)] if cols[0] == 'session'` там 287.67 MB.
- решил убрать создание лишнего массива
- улучшилась в несколько раз `MEMORY USAGE: 124 MB`
- `memory_profiler` - Показал что точка роста изменилась, теперь новая ТР `user_sessions = sessions.select { |session| session['user_id'] == user['id'] }` (104.07 MB).

### Ваша находка №2
- `ruby-prof: CallTree` - Показал что точка роста метод `String#split` там 32.82%.
- убрал лишние `split` в методах `parse_user`, `parse_session`
- улучшилась `MEMORY USAGE: 91 MB`
- `ruby-prof: CallTree` - Показал что точка роста метод `each` там 35.69%, а метод `split` уменшился до 27.00%

### Ваша находка №3
- `ruby-prof: CallStack` - Показал что точка роста метод `each` там 56.63%.
- решил провести рефакторин групируя сессии и нужные поля зарание
- улучшилась `MEMORY USAGE: 31 MB`
- `ruby-prof: CallStack` - Показал что точка роста метод `split` там 60.3%

### Ваша находка №4
- `memory_profiler` - Показал что точка роста метод `split` для парсинга файла на 1_000_000 строк. `MEMORY USAGE: 461 MB`
- решил провести рефакторин читая файл построчна и собрав информацию для пользователя сразу записать в результат файл
- улучшилась `MEMORY USAGE: 22 MB`
- `memory_profiler` - Показал что точка роста осталса метод `split`

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *420 MB, до 22 MB* и уложиться в заданный бюджет.

*Пробовал использовать метод `split` с блоком но по использовании памяти изминений не заметил разве что немного изменилось количество созданных обьектов*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *не написал*
