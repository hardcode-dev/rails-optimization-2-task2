# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: количество потребляемой памяти при обработке файла в 10 000 строк.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
Переписал тест используя Rspec matchers - изменил логику проверки соответствия ожидаемого и полученного результата (сравниваются значения по ключам хэшей)

Также добавил проверку на количество потребляемой памяти, используя `perform_allocation`

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений.

Вот как я построил `feedback_loop`:
1. Написал тест используя Rspec, с проверкой логики выполнения и количеству потребляемой памяти. *(после каждой оптимизации проверяю)*
2. Подготовил файлы для профилирования:
 - memory_profiler.rb - для отдельного профилирования с помощью гема `Memory profiler`
 - profilers.rb - генерирует отчёты для `Ruby-prof` в режиме профилирования аллокаций в формате Flat, Graph, Callstac, а также в режиме профилирования памяти в формате CallTree. И генерирует отчёты для `Stackprof` - пользовался редко, в основном смотрел визуализацию графа.
3. Установил Vallgrind + Massif для наблюдения за потреблением памяти в динамике

## Вникаем в детали системы, чтобы найти главные точки роста
Изучаем, что показывает `GS.stat`, `ObjectSpace.count`. На 10 000 строках видим работу GC:
```log
:total_allocated_objects => 398540,
:total_freed_objects => 282935,
```
Было освобождено достаточно много объектов, это говорит о том, что GC в Ruby v3.3.0 работает достаточно эффективно. Также это подтверждается замером с помощью `Memory profiler` - всего было использовано 767MB, а осталось 4,24KB (в уроке оставалось 5,76МБ)

Использование Memory profiler начинает показывать первые точки роста

### Ваша находка №1
- MemoryProfiler показывает главную точку роста - неэффективное добавление элементов в массив - при заполнении массивов sessions и users.
- переписал добавление элемента в массив без инициирования дополнительных элементов
- Метрика изменилась с 767МБ до 245МБ
- Неэффективное сложение массивов использовалось в двух местах: 506МБ и 18МБ. После оптимизации оба метода стали использовать одинаковое количество памяти - 530КБ, хотя в первом месте метод вызывается чаще в несколько раз. Интересно...

### Ваша находка №2
- Stackprof, Graphviz.dot, Ruby-prof:flat - показывают, что по количеству аллокаций Array#select является точкой роста
- Чтобы улучшить производительность создал вспомогательную хэш-таблицу в которой сгруппировал сессии по *user_id*
- Метрика изменилась с 245МБ до 63МБ
- Array#select занимал 182МБ, теперь 26МБ

### Ваша находка №3
- MemoryProfiler показывает что второй случай со сложением массивов начинает являться точкой роста с 17МБ. Оптимизируем как и в первом кейсе.
- Метрика изменилась с 63МБ до 46МБ
- строка со сложением стала занимать 730КБ вместо 17МБ, количество всех массивов уменьшилось с 65028 до 60972

### Ваша находка №4
- MemoryProfiler указывает на строку с парсингом даты. Оптимизируем
- Метрика изменилась с 46МБ до 35МБ
- строка с датой занимала *13МБ* и аллоцировала *171163 (!)* объекта. После оптимизации стала занимать *1МБ с 9929 объектами*. Очень наглядная оптимизация :smirk:

### Ваша находка №5
- Ruby-prof: flat, graph, callstack, KCacheGrind показывает что Array#all? является точкой роста. Избавляемся от его применения, так как этот метод создаёт ещё три дополнительных объекта
- Метрика практически не изменилась: с 35 до 34 МБ
- строка  занимала 1МБ, стала 183КБ

### Ваша находка №5
- Дальнейшее профилирование указывает на split (это необходимо) и генерацию и накопление массивов с пользователями и сессиями. Valgrind Massif показывает что с увеличением количество строк расход памяти значительно возрастает
- Поэтому решаем переписать программу на потоковый режим работы. В память будет загружаться информация о пользователе и его сессиях, считаться статистика, и записываться в файл. После чего в память будет загружаться следующий пользователь.
- Метрика показывает результат выполнения 29МБ. Причём как на 10_000, так и на 3_250_940 строк (файл data_large.txt). Это означает, что мы вложились в бюджет (< 70МБ). Ура! :smiley:

### Остальные находки
- В процессе оптимизации программы визуально выявляются ещё достаточное количество мест, которые, как кажется, можно оптимизировать. Но так как это будет хлопотно и нецелесообразно, а в бюджет уже укладываемся - то оставляем без изменений

## Результаты
- В результате проделанной оптимизации наконец удалось обработать файл с данными. Удалось улучшить метрику системы с 767МБ до 29МБ и уложиться в заданный бюджет.
- Приобрел практические навыки в оптимизации используемой памяти в работе приложений
- На практике выявил сильную взаимосвязь между оптимизацией CPU и памятью
- Закрепил навыки по построению эффективного `Feedback-loop`

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написал тест для проверки потребляемой памяти и количества аллоцированных объектов.
