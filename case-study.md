# Case-study оптимизации

## Актуальная проблема
У нас есть программа, которая принимает на вход файл с информацией о сессиях юзеров в своем особом текстовом формате,
и выдает отчет о сессиях в формате json.
Раньше все было хорошо, но теперь возникла необходимость запускать программу на чугунном утюге, поэтому необходимо,
чтобы на протяжении всей работы она **не потребляла больше 70Мб оперативной памяти.**

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы
при оптимизации.

## Feedback-Loop
Для построения эффективного фидбек лупа, нам нужен тест, который будет замерять потребляемую память процесса на
протяжении всей работы.
В rspec-benchmark есть инструменты для замера аллокаций, но не объема памяти. Поэтому мы напишем простой тест используя
возможности ОС.
```ruby
class TestMemoryUsage
  def run
    work_thread = Thread.new do
      work(data_path('data_large.txt'))
    end
    loop do
      sleep(0.1)
      usage = check_memory_usage
      puts "#{usage}Mb"
      if usage > 70
        puts 'Memory usage got higher the limit'
        Thread.exit
      end
      break if !work_thread.status
    end
    work_thread.join
  end

  def check_memory_usage
    (`ps -o rss= -p #{Process.pid}`.to_i / 1024.0).round(2)
  end
end

TestMemoryUsage.new.run
```

Тред для чека памяти будет нести с собой небольшой оверхед по памяти, и мы не сможем гарантировать, что скачков не было
между замерами, но в любом случае, по мере приближения к заданному бюджету мы сможем более точно проверить результат
с помощью valgrind massif visualizer.

Попробуем запустить тест.
```
52.27Mb
75.29Mb
Memory usage got higher the limit
```

Он ожидаемо падает!

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался гемом memory_profiler.
Попытка получить репорт по обработке целевого файла быстро съела 30Гб оперативы и начала свопать диск,
поэтому попробуем профилировать на меньшем объеме данных, но достаточно большом, чтобы не нарушить общую картину
расхода памяти. Для наших целей сгенерим файл со 100_000 юзеров.

### Итерация 1
Хорошие новости - нет retained данных, скрипт написан таким образом, что вся память вычищается GC.
Отчет мемори профайлера показал, что подавляющее большинство памяти уходит на стринги. И большая часть строк
аллоцируется строкой 57: `cols = l.split(',')`. Эту же запятую мы видим в топе аллоцированных строк:
```
359870  "session"
224935  "user"
194936  ","
```

Пока исходя из отчета возможная точка роста - уменьшение количества аллокаций по строкам. Попробуем посмотреть на
программу также с помощью ruby-prof в режиме профилирования памяти.
Ruby-prof также указывает на итерацию `#each_line` и `#split` который вызывается внутри него.
Чтож, попробуем для начала просто сократить количество памяти выделяемой на строки — зафризим в константах
все строковые литералы, которые используются больше одного раза:
```
USER_STR = 'user'.freeze
SESSION_STR = 'session'.freeze
COMMA_STR = ','.freeze
COMMA_SPACE_STR = ', '.freeze
MIN_STR = 'min.'.freeze
SPACE_STR = ' '.freeze
```

Попробуем посмотреть на наш тест и отчеты профайлеров после улучшения.
Похоже не помогло — суммарное потребление памяти программы на файле со 100000 юезров снизилось примерно на 10%.
Наш нехитрый тест на превышение бюджета по прежнему не проходит.
Большая часть аллокаций по прежнему происходит в методе `#split`.

### Итерация 2
Попробуем посмотреть на valgrind massiff. Из графика видно, что после инициализации программы, память приростает
линейно примерно с одной скоростью и достигает пика в конце исполнения. Если подумать о том, как работает код,
то станет понятно, что память сначала выделяется на наш список сессий и юзеров, которые код вычитывает из файла,
и затем оседает в результирующем хеше, в котором мы накапливаем отчет. Соответственно, мы никак не сможем достигнуть
выделенного бюджета, пока не избавимся от этих точек расхода памяти.

Подавляющее большинство данных отчета — это данные по сессиям каждого юзера, поэтому мы можем кардинально снизить
потребление памяти, если данные по каждому юзеру будем сразу писать в json-отчет. А остальное собирать в память на лету
и дописывать в конце, после обработки всех юзеров.

Метод `#work` теперь будет выглядеть следующим образом:
```ruby
def work(file_name, disable_gc: false)
  GC.disable if disable_gc

  users_count = `grep -R "^user" #{file_name} | wc -l`.strip.to_i
  lines_count = `wc -l #{file_name}`.strip.to_i
  last_line_index = lines_count - 1

  result = File.open('result.json', 'w')
  result.write(OPEN_CURB_STR + json_key('usersStats') + OPEN_CURB_STR) # {"usersStats":{
  total_sessions_count = 0
  unique_browsers = []

  current_user = nil

  File.open(file_name).each_line.with_index do |l, i|
    fields = l.split(COMMA_STR)
    if fields[0] == USER_STR
      if current_user
        write_user_stats(result, current_user)
        result.write(COMMA_STR)
      end

      current_user = parse_user(fields)
    end
    if fields[0] == SESSION_STR
      session = parse_session(fields)
      current_user.sessions << session

      total_sessions_count += 1
      unique_browsers << session[BROWSER_STR]
    end

    unique_browsers.uniq!
    # handle last user
    write_user_stats(result, current_user) if i == last_line_index
  end

  result.write(CLOSE_CURB_STR + COMMA_STR)
  result.write(json_key('totalUsers') + users_count.to_s + COMMA_STR)
  result.write(json_key('uniqueBrowsersCount') + unique_browsers.count.to_s + COMMA_STR)
  result.write(json_key('totalSessions') + total_sessions_count.to_s + COMMA_STR)
  result.write(json_key('allBrowsers') + QUOTE_STR + unique_browsers.map(&:upcase).sort.join(COMMA_STR) + QUOTE_STR)
  result.write(CLOSE_CURB_STR)

  result.close
end
```

Проверяем правильность работы программы. После небольшой модификации формата джейсона выясняем что программа работает
правильно. Наш тест использования памяти теперь проходит с запасом — УРА!
```
vshvedchenko@seymour: ~/workspace/rails-optimization-task2/test (master●) $ ruby memory-test.rb
30.09Mb
30.11Mb
36.61Mb
...
39.97Mb
39.97Mb
39.97Mb
```
Использование памяти в топе меньше 40Мб.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными на чугунном утюге.
Удалось улучшить метрику системы с почти гигабайта до 40Мб.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы будем использовать наш нехитрый тест.
