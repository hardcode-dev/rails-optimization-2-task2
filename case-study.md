# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: потребление памяти в мегабайтах.
В начале программы (до расчетов) фиксируется потребление памяти около 30 мб.
В качестве целевого результата обозначим потребление памяти (в конце работы программы) для алгоритма обрабатывающего 200 000 строк близким к 30-32 мегабайтам.
До оптимизации алгоритм обрабатывающий 200 000 строк потреблял около 55 мегабайт.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10 секунд.

Вот как я построил `feedback_loop`:
0. пишем тест на регресс производительности
1. запускаем профилировщик, находим главную точку роста
2. делаем необходимые оптимизации
3. запускаем тесты
4. если тесты упали, возвращаемся к шагу 3 и повторяем пока тесты не поезеленеют
5. смотрим как изменилась производительность, запускаем профилировщики, убеждаемся, что точка роста изменилась.
Уменьшаем пороговоре значение теста. Если уложились в бюджет завершаем loop.
6. Возвращаемся к шагу 1.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
- gem memory profile
- stackprof
- ruby prof (flat, callstack, graph, callgrind)
- valgrind massif visualier

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- Отчет stackprof показал, что главной точкой роста является место, где даты сессии собираются в массив, парсятся, и приводятся в определенный формат.
Ruby prof в режиме allocations (flat printer) показал, что главной точкой роста является String#split.
Graph printer показал, что главной точкой роста является метод Array::each, внутри которого вызывается map, внутри которого вызывается Date::parse.
Так как два отчета показали на парсинг даты, будем оптимизировать именно это место.
- как оптимизировал: Убрал ненужный парсинг и конвертацию дат. Вместо map, sort, reverse использовал соответствующие bang методы
- как изменилась метрика: потребление памяти для 200 000 строк не уменьшилось.
- как изменился отчёт профилировщика: выбранное для оптимизации место пропало из топов профилировщиков

### Ваша находка №2
- какой отчёт показал главную точку роста: Callgrind показал, что основной точкой роста теперь является String::Split.
 Он вызывается 400 000 раз (в 2 раза больше чем количество строк), из которых 200 000 вызывается из метода each, 170 000 из метода parse_session и 30 000 раз из метода parse_user.
 Всего потребляет 109 мб. Flat в режиме memory подтвердил это.
 Graph в режиме memory также подтвердил это, но показал главную точку роста через цупочку IO::each -> parse session
- как вы решили её оптимизировать: оказалось, что если методу split передать блок, то он не будет создавать промежуточных объектов. Переписал таким образом, чтобы split принимал блок, и внутри него накапливаю необходимые для статистики массивы для текущего юзера. Потом, когда наступает очередь следующего юзера, эти массивы очищаются и переиспользуются.
- как изменилась метрика: потребление памяти для 200 000 строк упало до 32 мб.
- как изменился отчёт профилировщика: Отчеты начали указывать на IO::write, количество вызовов split уменьшилось вдвое.

### Ваша находка №3
- Отчеты callgrind, flat, graph, и callstack показали что главной точкой роста теперь является IO::write
- как вы решили её оптимизировать: переделал отдельные вызовы File.write на блок File.open со всеми операциями внутри него.
- как изменилась метрика: потребление памяти уменьшить не удалось
- как изменился отчёт профилировщика: IO::write ушел с первых позиции профилировщиков

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы (потребление памяти при обработке 200 000 строк) с 55 мб до 32 мб и уложиться в заданный бюджет.

Алгоритм работает почти в 2 раза быстрее по сравнению с итогами оптимизации из первого задания (16 сек против 30 сек).
Отсюда можно сделать вывод, что работа GC имеет значительное влияние и на время выполнения алгоритмов (не только потребление памяти),
за счет остановок при сборке мусора.
Поэтому не генерируйте, товарищи, объекты лишний раз!

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы к тесту который проверял валидность алгоритма, я добавил тест, который рассчитывает потребление памяти этим алгоритмом.
В конце алгоритм возвращает зафиксированный в конце работы скрипта объем памяти, и тест использует его для проверки того факта, что этот объем не превышает нижнее пороговое значение заданное для текущей итерации оптимизации.
Тест располагается по пути spec/report/report_spec.rb.

## Checklist
- [x] Построить и проанализировать отчёт гемом `memory_profiler`
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `Flat`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `Graph`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `CallStack`;
- [x] Построить и проанализировать отчёт `ruby-prof` в режиме `CallTree` c визуализацией в `QCachegrind`;
- [x] Построить и проанализировать текстовый отчёт `stackprof`;
- [ ] Построить и проанализировать отчёт `flamegraph` с помощью `stackprof` и визуализировать его в `speedscope.app`;
- [x] Построить график потребления памяти в `valgrind massif visualier` и включить скриншот в описание вашего `PR`;
- [x] Написать тест, на то что программа укладывается в бюджет по памяти

![alt text](https://github.com/aworldx/rails-optimization-task2/blob/opt/image.png?raw=true)