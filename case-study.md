# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *измерение потребляемой памяти*

Для начала используя ассимптотку я сделал предположение о том, сколько памяти будет потреблять программа на больших данных.
Для этого я написал простой тест, который запускает программу, передавая ей в качестве аргумента нужный файл

### Результаты (с отключеным GC):
* 12500 строк ~ 104 Mb (530 Mb)
* 25000 строк ~ 137 Mb (1952 Mb)
* 50000 строк ~ 239 Mb (7527 Mb)

Исходя из этих результатов можно сделать вывод что для обработки 3250940 строк нужно чуть менее терабайта памяти (с отключеным GC).
## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *несколько секнуд*

Вот как я построил `feedback_loop`:
1. Написал performance тест для защиты от деградации производительности
2. Написал програмки для запуска различных профилировщиков.
3. Подключил Guard чтобы не тратить время на ручной запуск тестов

Сам `feedback_loop`:
1. запуск профилировщиков и выявление наиболее жирных мест.
1.1. Рефакторинг, если плохо понятно в каком именно месте программы узкое место
1.2. Запуск тестов
1.2. Goto 1
2. Внесение необходимых изменений
3. Запуск тестов
3.1. Откат изменений если тесты не прошли
4. Если метрика не соответствует бюджету - Goto 1

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *stackprof, ruby-prof, memory-profiler & valgrind*

Вот какие проблемы удалось найти и решить

### Находка №1
- Исходя из бюджета метрики, очевидно что программу надо перписать в потоковом стиле, т.е. обработка и сбор информации должны быть строка за строкой
- Переписал программу в потоковом стиле.
- Метрика улучшилась. При разборе 50000 строк потребляется 42 Mb памяти (вместо 239 Mb ранее)
- Теперь можно переходить к профилированию

### Находка №2
- Для начала сформировал отчет в stackprof. Главная точка роста - Date.parse. То же самое показали и отчеты ruby-prof. Memory profiler, так же указал на эту строку.
- Вместо парсинга даты и затем приведения к формату iso8601, мы можем просто убрать лишний перенос строки в конце. Дата в самом файле лежит уже в нужном нам формате
- Для 95000 записей потребление памяти уменьшилось на 1 Мб с 70 до 69
- Это место перестало быть главной точкой роста.

### Находка №3
- Отчеты memprof и ruby-prof показали главную точку роста - string.split при разбиении строки файла на колонки. Странно. Попробовал увеличить кол-во строк файла до 2,5 млн в отчете memory_profiler. Получил совсем другую картину. Главная точка роста - `session['browser'].upcase.match?(/INTERNET EXPLORER/)`
- Здесь мы можем искользовать более быстрые `start_with?` вместо `match?`, а также делать upcase ранее, т.к. для браузер участвует несколько раз при вычислениии отчета
- Метрика не изменилась.
- Отчет профилировщика изменился, потребление памяти снизилось, теперь главная точка роста - string#split при парсинге сессии.

### Находка №4
- В данном случае парсинг сессии избыточен по памяти, т.к. там мы создаем дополнительных хеш, а также зачем-то сплитим еще раз исходную строку.
- Убрал метод parse_session за ненадобностью
- Метрика не изменилась.
- Отчет профилировщика изменился, потребление памяти снизилось, теперь главная точка роста - `cols = line.split(',')`.

### Находка №5
- При расчете бенчмарка был выключен GC!!! Вот это да...
- Потребление памяти для всего файла составляет 965 МБ с включенным GC

### Находка №6
- Убрал вывод потребляемой памяти из метода `work`, и профилировщик memory_profiler построил иной отчет! Главная точка роста - преобразование хеша в json.
- Попробовал использовать гем oj, но не получил большого профита с включенным GC. Поэтому откатился, и на всякий случай запустил опять memory_profiler. И, о чудо, снова другой отчет, и в третий раз запустил, и он опять другой... Не понимаю что происходит. Главные точки роста получаются разные, то это `line.split(',')`, то создание очередного хеша для хранения информации о сессиях пользователей. Вынес откл/вкл GC из программы в скрипт с профайлером, memory_profiler начал выполняться очень долго (5 минут), при этом начал отжирать 12.5 Gb памяти. Какой-то глюк. Буду придерживаться первого варианта, тем более что он очень похож на правду. Сделал запись в файл по мере накопления информации по каждому пользователю.
- Метрика значительно улучшилась. Парсинг всего файла занимает 150 мб
- Отчет профилировщика сильно изменился. Наконец показывает объем памяти, близкий к реальному - `Total allocated: 2.23 GB (28188450 objects)` а не как раньше - пара килобайт. Что-то определенно не так с профайлером (или со мной).

### Находка №7
- Главная точка роста `cols = line.split(',')`. Она конечно вызывается для каждой строки, но память можно резко уменьшить изменив другую строку
- Заменил `File.read(filename).split("\n") do` на `File.open(filename, 'r').each do`
- Метрика уложилась в бюджет


## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы до 22 Мб и уложиться в заданный бюджет.

При этом мне осталось неясным, почему ни один из профилировщиков не показал мне истиную точку роста - чтение файла? Что я делал не так?
Почему memory_profiler генерировал разные по содержанию отчеты на одну и ту же программу?

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написан тест для замерения потребляемой помяти. Пороговое значение я поставил в 35 мб (видимо rspec подгружает еще что-то при исполнении спек).
