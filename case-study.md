## Предварительная подготовка

Тут все довольно очевидно и ± как в прошлом задании. 
- Разношу код из `task-2.rb` по классам и файлам.
- Нарезаю сэмплы которыми буду пользоваться.

## Выстраивание Feedback loop

- создаю класс FastReportBuilder с тем же контрактом, в котором будет переписанный код
- начинаю выстраивать feedback loop
- использую строчку из README чтобы смотреть потребленную память в конце выполнения
- использую memory-profiler чтобы видеть на что выделялась память
- в итоге прихожу к двум режима запуска, между которыми можно свободно переключаться
  - `ruby task-2.rb`: "быстрый" запуск: без профайлера, с тестами, в конце показывается итоговое значение потребленной памяти
  - `MEM_PROF=1 ruby task-2.rb`: "подробный запуск" с профайлером memory-profiler, чтобы смотреть куда уходила память.
- быстро переключаясь между этими двумя командами можно эффективно оптимизировать программу

## Главные точки роста

Тут прямо из описания задания понятно что нужна построчная обработка "на лету", поэтому пока даже не имеет смысл запускать профилировщики.
- принимаю решение сначала переписать программу на построчную обработку, а потом оптимизировать то что получилось

## Рефакторинг

- гуглю как читать файл построчно, копирую ответ со stackoverflow.
- используя куски кода по обработке индивидуальных юзеров из своего первого задания, накидываю работающий прототип
- проверки / багфикс / улучшения
- прогоняю тесты и вижу что они падают, хотя отчет выглядит нормально
  - начинаю сравнивать и вижу что в этом задании, в отличии от прошлого, тесты ждут полный список браузеров пользователя вместо уникального
  - не понимаю опечатка это или так задумано, но решаю считать тесты ожидаемым поведением и меняю свой код
  - собирается полный список браузеров
- запускаю, отчет собирается за 49 секунд и показывает потребление памяти 735 Мб. 

В этом месте я уверен что бюджет -- 700 Мб. Поэтому цифра меня не смущает и я думаю что достаточно оптимизировать память в 2-3 раза и все будет ок.

## Первая оптимизация 

- запускаю профилировщик, смотрю отчет
```
allocated memory by class
-----------------------------------
 155.54 MB  File
 114.10 MB  String
  36.34 MB  Array 
```
- Очень много раз аллоцируется файл. 
- Смотрю в код, вижу такой паттерн
  - читаются строки из файла
  - есть начались сессию юзера, начинаем собирать инфу по юзеру
  - как только сессии кончились, пишем эту инфу в отчет и начинаем собирать по другому
  - в момент "пишем эту инфу в отчет" каждый раз переоткрываем файл отчета
- Понимаю что файл с отчетом надо открыть один раз в самом начале, передать его как параметр и писать в уже постоянно открытый
- Произвожу оптимизацию, смотрю отчет

```
allocated memory by class
-----------------------------------
 112.63 MB  String
  36.34 MB  Array
```

- Все хорошо, можно искать следующую точку роста

## Вторая оптимизация

- вижу что очень много раз аллоцируются строки `112.63 MB  String`
- в первую очередь решаю все зафризить
- пишу магический коммент в файл, фишку пару мест где теперь нельзя мутировать строки
- стало получше, но все еще много `85.67 MB  String`
- память потребляется на 101 строке
  - там код вида `cols = line.gsub("\n", '').split(',')`
  - решаю избавиться от gsub
  - нахожу параметр `chomp: true` который обрезает ньюлайны при чтении файла
  - gsub теперь не нужен
- потребление стало `67.26 MB  String`, меньше почти в два раза

## Третья оптимизация

- проблема все еще в строках, ищу потенциально проблемные места
- upcase вызывается в нескольких местах, избавляюсь от него
- потребление памяти для полного файла упало до 500 Мб

В этот момент до меня доходит что бюджет не 700 а всего 70, а значит в него еще попадать и попадать.
Но строки по-прежнему аллоцируют максимальное количество памяти, все остальные методы тратят меньше 70. Решаю продолжать оптимизацию с ними

## Четвертая оптимизация

- строки все еще главная точка роста
- особенно строчка на которой делается `.split(',')`
- понимаю (и по отчету видно) что строки в процессе сплита не фризится поэтому создаются сотни тысяч 'sessions' и имен бразуеров
- понимаю что надо как-то их зафризить (или не создавать)
  - проблема оказывается серьезнее чем я ожидал
  - нормального решения "зафризить" сплит найти не удается
  - пробую выносить его в другие методы или переиспользовать  
  - пробую делать to_sym и freeze но они вызываются уже "после" того как память аллоцировалась
  - стековерфлоу предлагает какие-то поехавшие решения вроде `.each_codepoint` что выглядит явным оверкиллом для тестового задания
  - на третьем часу узнаю что в 2.6 руби добавили возможность передавать блок чтобы сплит сразу обрабатывал строку а не создавал ее
  - не помогает, память все еще аллоцируется
- в результате того что по описанным выше причинам я много раз запускаю программу для разных файлов, в какой-то момент до меня доходит что потребляемая память значимо меняется от размера файла, чего по идее происходить не должно
- минуты за 2 нахожу ошибку в потоковом считывании 
  - меняю `.readlines` на `.each_line` и моментально попадают в бюджет с потреблением около 20 мегабайт в конце для любого файла
  - отчет собирается секунд за 10
  
Получается если бы не эта дурацкая ошибка в начале из-за невнимательности, в бюджет бы я попал значительно раньше и задание бы заняло не 8 часов, а 3-4.

Еще задним числом понятно что надо было сразу проверить ассимптотику и не переходить к оптимизациям пока потребление памяти не перестанет зависеть от размера файла. Скорее всего я бы начал это делать если бы понял что не попал в бюджет с десятикратной разницей, но тк изначально я считал что он 700, меня не смутило, что программа занимает те же 700.

Ну, тоже опыт.
  
Коммичу, пишу тесты, оформляю PR, разворачиваю валграйнд массиф и проверяю потребление во время работы программы. 


## Результаты
- После переписывания программа потребляет не более 42 Мб памяти для большого файла во время работы
- После завершнения -- всего 22 Мб

## Защита от регрессии производительности
- написал тест на потребление памяти
  - на самом деле пришлось подгонять значения чего я не очень люблю. Написать тест который проходит было элементарно, но я хотел чтобы он ломался если бы я отключал самую главную оптимизацию. А этого добиться толком не получалось, тк на маленьких файлах выгоды практически нет, а с большими тест слишком долго висит (гораздо дольше чем запуск того же кода в feedback loop)
  - в результате эмпирически удалось подобрать размер файла который проходит более-менее вменяемое время (но все равно очень долго для юнит-теста) и ломается если заменить обратно `each_line` на ошибочный `readlines`
  - но он мне все еще не нравится, слишком маленькая разница между значениями. Тест потенциально может начать падать при валидных изменениях.