# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго,
и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал
использовать замер оперативной памяти во время выполнения программы относительно обьема загружаемых данных.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения
логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`,
который позволил мне получать обратную связь по эффективности сделанных изменений за *~60sec*.

Вот как я построил `feedback_loop`. С начала я решил определить размер данным с которым я могу достаточно
быстро получить результат работы программы. Для этого я постепенно делил размер данных на два, в итоге получил список
файлов, который позволял эффективно управлять нагрузкой программы в процессе ее оптимизации. Список файлов получился
в виде: `data_large_512x.txt`, `data_large_256x.txt`, `data_large_128x.txt`, `data_large_64x.txt`,
`data_large_32x.txt`,`data_large_16x.txt`, `data_large_8x.txt`, `data_large_4x.txt`, `data_large_2x.txt`,
`data_large.txt`.

Первым файлом, который откликнулся за разумное время был файл под названием `data_large_64x.txt` учитывая это я
решил проводить замеры памяти:

```
FILE: data_large.txt
MEMORY USE AT START: 19 MB
MEMORY USAGE AFTER READING FILE: 478 MB
# Не можем дождатся выполнения программы

FILE: data_large_64x.txt
MEMORY USE AT START: 19 MB
MEMORY USAGE AFTER READING FILE: 25 MB
MEMORY USAGE: 521 MB
```

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался системной утилитой `ps`, `memory_profiler`,
`prof`

Вот какие проблемы удалось найти и решить

### Ваша находка №1
Первый вывод по точкам работы пограммы утилитой `ps` показал, что обьем роста памяти происходит по мере загрузки
файла в память. Исходя из потребления загрузкой файла памяти, я решил переписать полную загрузку файла в память на
построчную обработку. Потребление памяти уменьшилось почти `20 раз`:

```
MEMORY USAGE AFTER OPEN FILE: 25 MB
MEMORY USAGE AFTER COMPLETE APP: 27 MB
Finished in 4.85 seconds (files took 0.14152 seconds to load)
```

Результаты `memory_profiler` показали, что больше всего идет потребление памяти на строки и загрузку давнных
в память:
```bash
allocated memory by location
-----------------------------------
  22.04 MB  .../app.rb:31
   4.07 MB  .../app.rb:30
   3.24 MB  ../user.rb:31
   ....
   
allocated memory by class
-----------------------------------
  23.36 MB  String
  15.80 MB  Array
   4.21 MB  Hash
 563.54 kB  User
  16.86 kB  File
  224.00 B  JSON::Ext::Generator::State
  144.00 B  Thread::Mutex
   80.00 B  IO
   80.00 B  Process::Status
   40.00 B  App
```

### Ваша находка №2
После достижения положительного результата было принято решение пробовать обработать более крупный обьем данных
с файла `data_large_16x.txt`

```
MEMORY USAGE AFTER OPEN FILE: 26 MB
MEMORY USAGE AFTER COMPLETE APP: 84 MB
Finished in 1.14 seconds (files took 0.14153 seconds to load)
```

Из замеров видно, что память увеличивается по мере роста обрабатываемых данных. Имея такие замеры потребления
было принять решение писать отчет в файл по мере обработки данных без их полной загрузки в память с использованием
временного файла и последующего формирования на основании его итогового отчета.
Повнорные замеры показали уменьшение памяти:

```
MEMORY USAGE AFTER OPEN FILE: 26 MB
MEMORY USAGE AFTER COMPLETE APP: 54 MB
Finished in 20.42 seconds (files took 0.13694 seconds to load)
```

### Ваша находка №3
Дальнейшие иссдедования показали, что зависимость потлебления памяти от обьема данных сохраниется.
Было принять решение воспользоваться `ruby_prof` для определения точки роста:

```bash
 %self      total      self      wait     child     calls  name                           location
 53.43  55642600.000 55642600.000     0.000     0.000   203184   String#split
  9.00  104134288.000 9376760.000     0.000 94757528.000        1   IO#each_line
  6.61  6886440.000 6886440.000     0.000     0.000   172161   String#upcase
  6.00  6244840.000 6244840.000     0.000     0.000    31225   <Class::IO>#write
 ...
```

Из отчета видно, что идет потребление памяти при парсинге строк, но последовательное исследование строк работы программы
показало, что фактически парсинг строки не потребляет огромного количества памяти. Принято решение обратится
за данными к `memory_profiler`:

```bash
allocated memory by location
-----------------------------------
  66.56 MB  .../app.rb:60
  22.04 MB  .../app.rb:33
   7.40 MB  .../app.rb:81
   6.88 MB  .../app.rb:57
   4.07 MB  .../app.rb:32
  ...

allocated memory by class
-----------------------------------
  66.01 MB  File
  35.80 MB  String
  15.80 MB  Array
   1.75 MB  JSON::Ext::Generator::State
   1.35 MB  Hash
 563.69 kB  Thread::Mutex
 563.55 kB  User
  168.00 B  MatchData
   80.00 B  App
   80.00 B  IO
   80.00 B  Process::Status
```

Из данных видно, что класс `File` потребляет память, по мере роста читаемых и зааисываемых данных в файл.
Было принято решение отказаться от временного файла для формирования промежуточных данных и создавать отчет сразу
в единый файл. Так же было принято решение отказаться от класса `File` в пользу `IO` для непосредственного доступа
к файлу. Итог изменений оправдал ожидания при обработке всех данных при чистом запуске программы и при запуске тестов:

```bash
ruby app.rb
user     system      total        real
MEMORY USAGE AFTER OPEN FILE: 12 MB
MEMORY USAGE AFTER COMPLETE APP: 14 MB
30.899839  44.350610  75.253799 (429.961242)

rspec spec
MEMORY USAGE AFTER OPEN FILE: 26 MB
MEMORY USAGE AFTER COMPLETE APP: 28 MB
.

Finished in 6 minutes 55 seconds (files took 0.14137 seconds to load)
```

`ruby_prof`
```bash
 %self      total      self      wait     child     calls  name                           location
 99.98  16255568.000 16255000.000     0.000   568.000        1   IO#each_line
  0.00    608.000   608.000     0.000     0.000        1   Kernel#`
...
```

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.

`ruby-prof` в режиме `CallTree` c визуализацией в `QCachegrind` показал основное потребдение
памяти при чтении и записи файла:

| Point          | Percent |
|----------------|---------| 
| IO:open        | 99.99%  |
| IO:each_line   | 99.99%  |
| App:user_stats | 90.69%  |
| IO:write^      | 83.65%  |

Из полученных данных видно, что программа очень много тратит времени на работе класса `IO`.
Было принято решение вернутся к использованию класса `File` и использовать чтение и запись файла
в еданом открытом потоке. Результат для файла порабовал `data_large.txt`:

```bash
MEMORY USAGE AFTER OPEN FILE: 26 MB
MEMORY USAGE AFTER COMPLETE APP: 30 MB
.

Finished in 15.92 seconds (files took 0.20009 seconds to load)
1 example, 0 failures
```

Удалось улучшить метрику системы с *более чем 0.5Gb, до 30 MB* (в режиме тестирования) и уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был переписан с
помощью инструмента `RSpec` тест на результат работы программы.
Дополнительно к тестирование был добавлен тест на проверку потребления памяти в `30MB`.
