# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.
Необходимо было обработать файл с данными, чуть больше ста мегабайт.
У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго.
А также программа потребляла огромное кол-во памяти, так что пода перегружалась из-за OOM Killer (программа крутилась в kubernetes).

Такое положение дел нас не устраивало, поэтому необходимо решить эту проблему оптимизировав эту программу.
Программа не должна потреблять больше 70Мб памяти при обработке файла заданного объема в течение всей своей работы.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
Кол-во памяти потребляемое программой при своей работе.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`,
который позволил мне получать обратную связь по эффективности сделанных изменений за 4 минуты.

Вот как я построил `feedback_loop`:
Для начала, я отрезал куски от файла по 10_000, 20_000, 40_000 строк.
Далее с помощью вставки небольшого кода в конце программы я замерил скорость их выполнения.

```ruby
puts "MEMORY USAGE: %d MB" % (`ps -o rss= -p #{Process.pid}`.to_i / 1024)
```

Потреблемение памяти 66 MB, 82 MB и 126 MB соответсвенно.
По примерным подсчетам, при обработке полного объема информации в 3_250_940 строк должно выделиться 210 GB памяти

Поэтому в feedback_loop я буду использовать именно это кол-во строк.
При приближении к маленьким числам метрики можно будет увеличить тестируемый объем информации.
Для того чтобы не испортить и так не очень-то "хорошую" картину, я написал тест на текущую метрику.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory_profiler, stackprof и ruby-prof.

## Вот какие проблемы удалось найти и решить

### Дополнительные работы
Из бюджета очевидно, что мы не можем ни считывать файл в память целиком, ни накапливать в памяти данные по пользователям.
Это обозначает, что программу нужно переосмыслить и написать в "потоковом" стиле.
После переработки чтения файла в построчный вариант, программа потратила на обработку 40_000 строк 44 MB, т.е. в три раза меньше.

### Ваша находка №1
- memory_profiler показал, что на обработку 40_000 строк было выделено 1.72 GB, а главная точка роста файл report.rb строка 45 (@sessions.select { |session| session.user_id == user.id });
- Решил, что при парсинге строк сессий нужно сохранять объекты не в массив, а в хэш, где ключом будет user_id, а значением будет массив сессий;
- Метрика увеличилась до 50 MB, но обработка стала выполняться менее секунды;
- memory_profiler показал, что на обработку 40_000 строк было выделено 53.46 MB, что в практически в 32 раза меньше предыдущего показателя. Решение признал успешным.

### Ваша находка №2
- memory_profiler показал, точка роста файл parse_session.rb строка 4 (fields = line.chomp.split(','))
- fields = line.split(SPLITTER)[1..-1] и chomp переделал на chomp! и начал вызывать перед передачей строки в парсер, а создание объектов переделал на Session.new(\*fields)
- Метрика уменьшилась до 40 MB
- memory_profiler показал, что на обработку 40_000 строк было выделено 39.36 MB, а на обработку всего объема информации 1885 MB.
Также valgrind massif visualier показал небольшой прирост памяти с течением времени.
Т.е. по всей видимости хранить всю информации в памяти накладно, поэтому переделаю и вывод в файл в потоке. В памяти буду хранить только общую статистику, а информацию пользователей буду сразу записывать в файл.

## Результаты
В результате проделанной оптимизации наконец-то удалось обработать полный объем данных, потратив всего 38 MB.
Т.е. удалось улучшить метрику системы с 1885 MB (после перевода на потоковое чтение файла) до 38 MB и уложиться в заданный бюджет.
Самым лучшим решением было перевести обработку на потоковое чтение и запись.
Что интересно, обработка полного объема данных заняло чуть меньше 20 секунд.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал тест на максимальное выделение памяти.
