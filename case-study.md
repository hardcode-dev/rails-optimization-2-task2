# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала этим файлом после оптимизаций первого урока за 25с, но ела в процессе больше гигабайта памяти, требовалось решить эту проблему

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: 
размер памяти в любой момент времени не должен превышать 70МБ. 
Так как руби процесс не отдает память в ОС сам, то замерять было решено память в конце выполнения программы

mem = `ps -o rss= -p #{Process.pid}`.to_i / 1024
puts "MEMORY USAGE: %d MB (#{mem})"

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 
В качестве фидбек лупа я использовал парсинг трети исходного файла что позволило выполнять тест менее чем за 10 секунд

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался RubyProf

### Ваша находка №1
Честно говоря в силу того что в первом задании я уперся в 32с и никак не мог пойти дальше я еще там отказался от накопления данных
и был уверен что достаточно перестать грузить файл в память чтобы ужаться по памяти достаточно. Однако построковое чтение файла и запуск фидбек лупа показали что руби процесс ест больше гигабайта

Поэтому я запустил профилировку, выяснилось что конечно же создание результирующего хэша и сопустсвующих обьектов это огромная накладная статья
Это и была моя точка роста

Я переписал парсинг так, чтобы сразу писать в файл данные по мере их поступления, благо файл отсортирован по принципу юзер1 - его сессии - юзер2 - его сессии

В итоге потребление памяти снизилось до 15MB
MEMORY USAGE: %d MB (15)

А время работы снизилось на 10 секунд ( шок )
real	0m15.091s
user	0m14.581s
sys	0m0.336s

Дальнейший анализ отчетов профилировщика не показал ничего интересного, поэтому я решил что попрактикуюсь на реальном проекте


## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с более чем одного гигабайта до 15мб и уложиться в заданный бюджет.

А еще время работы уменьшилось на 10с что составляет порядка 40% и это после оптимизации по CPU!!!
И это при том что некоторые конструкции для процессора очевидно сложнее чем были раньше

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
