# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: потребление памяти при обработке файла data_large.txt

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за неделю.

Вот как я построил `feedback_loop`:  Итерации: замерял метрики, составлял отчет, находил точку роста, менял код, снова смотрел метрики и отчет.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался гемами memory-profiler, StackProf, ruby-prof, а также программой valgrind massif visualier.

Вот какие проблемы удалось найти и решить

### Находка №1 (файл - 10000 строк)
- memory_profiler (memory by location) показал точку роста в строке 55: sessions = sessions + [parse_session(line)] if cols[0] == 'session' (287668112 байт)
- использовать оператор '<<' для помещения элемента в конец массива без создания дополнительных объектов
- по памяти было 411 МБ, стало 136 МБ
- отчёт профилировщика изменился, теперь точка роста в строке 101: user_sessions = sessions.select { |session| session['user_id'] == user['id'] }

### Находка №2 (файл - 10000 строк)
- ruby-prof Flat показывает точку роста в Array#each. Где именно, неясно, полагаю. ruby-prof graph показывает тоже на Array#each, который внутри метода collect_stats_from_users
- убрал преобразования дат, так они ничего не меняют, сократил map в нескольких вызовах метода collect_stats_from_users
- по памяти было 50 МБ, стало 300 МБ
- отчёт профилировщика немного изменился, теперь точка роста в методе Object#parse_session

### Находка №3 (файл - 10000 строк)
- ruby-prof callstack показывает точку роста в Array#each, который в самом начале перебирает строки и парсит
- сделал то же, что в Находке №1 для строки с массивом users (применил оператор '<<'), убрал лишние split-ы в методах парсинга parse_user и parse_session, передаю туда сразу массив, а не строку
- по памяти было 308 МБ, стало 302 МБ
- отчёт профилировщика изменился, точка роста в Hash#merge

### Находка №4 (файл - 10000 строк)
- ruby-prof (calltree, qcachegrind) показывает точку роста в Array#each, самый мощный который в начале прогоняет split, затем Hash#merge, потом parse_session
- убралллл объявление переменной в методах parse_session, parse_user
- по памяти было 302 МБ, стало 302 МБ
- отчёт профилировщика не изменился

### Находка №5 (файл - 10000 строк)
- stackprof показывает точку роста в строке 51: cols = line.split(',')
- зафризил строку ','
- по памяти было 304 МБ, стало 305 МБ, но объектов стало создаваться меньше в этой строке на 10 тысяч
- отчет показывает снижение аллокации в этой строке, но она все еще точка роста.

### Находка №5 (файл - 10000 строк)
- вернувшись к memory_profiler понял, что основные точки роста в parse_session, parse_user и collect_stats_from_users
- зафризил строковые литералы и поменял строковые ключи на символы
- по памяти было 304 МБ, стало 86 МБ
- отчет показывает точку роста в строке 100: user_sessions = sessions.select { |session| session[:user_id] == user[:id] }

### Находка №5 (файл - 10000 строк)
- здесь select затратный: user_sessions = sessions.select { |session| session[:user_id] == user[:id] }
- переписал весь блок с использованием группировки сессий по user_id
- по памяти было 86 МБ, стало 68 МБ
- отчет показывает точку роста в строке 52: cols = line.split(','.freeze)


Алгоритм работы переписанной программы:

Так же проходим по файлу data_large.txt по одной строке.
две локальных переменных user и user_session
четыре глобальных переменных totalUsers, totalSessions, allBrowsers, uniqueBrowsersCount

1) если строка - юзер, то увеличиваем totalUsers, обрабатываем предыдущего юзера (считаем его статистику, если он есть) и переписываем переменную user
  сбор статистики юзера:

  собираем минуты в массив mins, браузеры - в browsers, даты - в dates, затем вычисляем все параметры статистики юзера;
  тут же вычиcляем allBrowsers, конкатенируя к нему browsers и делая uniq!

  Записываем строку статистики юзера в файл result.txt

2) если сессия - увеличиваем totalSessions, складываем ее в массив user_sessions.

На этом итерации заканчиваются.

3) записываем значения глобальных переменных в файл result.txt, добавив необходимые скобки


## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с нескольких гигабайт до 28 мегабайт и уложиться в заданный бюджет.

1) Асимптотика перед выполнением:

10_000 строк - 88 МБ
20_000 строк - 98 МБ
40_000 строк - 136 МБ

2) Не понял, как читать отчет flamegraph с помощью speedscope, режим :object StackProf делал и все равно там по памяти не смог ничего найти. Только по времени отчет.

3) Хотелось бы узнать, можно ли с помощью valgrind и massif профильнуть кусок кода в рельсовом проекте. Как это лучше сделать?

Программа обрабатывает файл data_large.txt за примерно 33-38 секунд.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал тест на замер памяти, но он для файла размером 1000 строк.
Не думаю, что надо писать тест для data_large.txt, так как даже файл на 100000 строк выполняется очень долго.
