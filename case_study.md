# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я решил использовать профилировщик rubyprof в режиме memory, а так же выводить потребление памяти системным процессом в нескольких местах кода

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений примерно за 10 секунд

Вот как я построил `feedback_loop`:
Я разбил файл data_large.txt на несколько файлов с 1%, 5%, 10% и 50% от общего объема данных
Замеры начинались на 1% данных, что позволяло уложиться в 10 сек.
При видимом улучшении показателя потребляемой памяти изменения коммитились
При значительном снижении потребляемой памяти и времени работы программы постеменно увеличивался объем данных

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался отчетом ruby-prof в формате cachegrind

Первые замеры (1% данных):
- время выполнения программы: 10.38 сек
- потребление памяти: 420мб

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- Из отчета стало очевидно, что считывать файл в память, фомировать отчеты и уже после записывать в файл - слишком "дорого"
- Было решено переделать программу на формирование отчета по каждому пользователю, записи этого отчета в файл, обнуления пользователя в памяти и переход к следующему
Так же для отчета по статистике были использованы переменные-счетчики, которые обновлялись по мере чтения информации по каждому пользователю, а для хранения уникальных названий браузеров был выбран `SortedSet`
Отчет по пользователям писался в отдельный файл, после чего в финальный отчет записывался отчет по статистике, считывался файл с отчетами по каждому пользователю и последовательно дописывался в финальный отчет
- В результате время выполнения программы и потребление памяти значительно сократились, но до попадания в бюджет было еще далеко

Замеры во итогу (полный объем данных):
- время выполнения программы: 6.65 сек
- потребление памяти: 169 мб

### Ваша находка №2
- отчет rubyprof показал, что основное потребление памяти связано с повторным чтением из файла (`each_line`), в который писались отчеты по пользователям
стало очевидно, что использование временного вспомогательного файла хоть и дало результаты, но их явно недостаточно
- было решено писать отчеты по пользователям сразу в итоговый отчет, так же использовать счетчики для отчета по статистике и записывать статистику уже в конец файла. Это позволило бы избавиться от лишних операций с дополнительным файлом
- после некоторых "мучений" с формированием обоих отчетов в один синтаксически корректный .json файл результат был достигнут
- повторные запуски теста с выводом потребления памяти системным процессом показывали разные результаты, но каждый раз укладывались в бюджет

Замеры по итогу (полный объем данных)
- время работы программы: 6.4 сек
- потребление памяти от 19 до 36 мб

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 420 мб на 1% данных, до ~30 мб на полном объеме и уложиться в заданный бюджет.

Время выполнения программы так же значительно сократилось.

## Защита от регрессии производительности
Так как отчеты по потребляемой памяти разнились от запуска к запуску, для защиты от потери достигнутого прогресса при дальнейших изменениях программы использовались максимальные из полученных значения по памяти, а так же простой тест на корректность формирования самого отчета
